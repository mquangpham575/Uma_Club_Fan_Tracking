import asyncio
import json
import os
import sys
from pathlib import Path
import pandas as pd
import zendriver as zd
import gspread
from google.oauth2.service_account import Credentials
import time

from globals import CLUBS, SHEET_ID


# ========== Google Sheets config ==========
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
CREDS = Credentials.from_service_account_file("credentials.json", scopes=SCOPES)
GC = gspread.authorize(CREDS)


# === Club selection ===
def pick_club() -> dict | str:
    print("=== Choose a club to export ===")
    for key, cfg in CLUBS.items():
        print(f"{key}. {cfg['title']}")
    print("0. Export ALL clubs (default)")
    choice = input("Enter 0‚Äì7 [default=0]: ").strip()
    if choice == "" or choice == "0":
        return "ALL"
    if choice not in CLUBS:
        print("Invalid choice, defaulting to 1.")
        choice = "1"
    return CLUBS[choice]


# === Paths ===
def resolve_base_dir() -> Path:
    if getattr(sys, "frozen", False):
        return Path(sys.executable).parent
    return Path(__file__).parent


# === Data fetch ===
async def fetch_json(URL: str):
    MAX_RETRIES = 3
    RETRY_DELAY = 5
    
    for attempt in range(MAX_RETRIES):
        browser = None
        try:
            browser = await zd.start(
                browser="edge",
                browser_executable_path="C:/Program Files (x86)/Microsoft/Edge/Application/msedge.exe"
            )
            page = await browser.get("https://google.com")
            
            async with page.expect_request(r".*\/api\/club_profile.*") as req:
                await page.get(URL)
                await req.value
                body, _ = await req.response_body
            
            text = body.decode("utf-8", errors="replace") if isinstance(body, (bytes, bytearray)) else str(body)
            return json.loads(text)
            
        except (zd.errors.RemoteDisconnectedError, zd.errors.ConnectionAbortedError) as e:
            print(f"L·ªói k·∫øt n·ªëi ({URL}, l·∫ßn {attempt + 1}/{MAX_RETRIES}): {type(e).__name__}. ƒêang th·ª≠ l·∫°i sau {RETRY_DELAY}s...")
            if attempt < MAX_RETRIES - 1:
                if browser:
                    await browser.stop()
                await asyncio.sleep(RETRY_DELAY)
                continue
            else:
                raise
                
        except Exception as e:
            raise e
            
        finally:
            if browser:
                await browser.stop()
    
    raise Exception(f"Th·∫•t b·∫°i sau {MAX_RETRIES} l·∫ßn th·ª≠.")


# === DataFrame processing ===
def build_dataframe(data: dict) -> pd.DataFrame:
    df = pd.json_normalize(data.get("club_friend_history") or [])
    for c in ("friend_viewer_id", "friend_name", "actual_date", "adjusted_interpolated_fan_gain"):
        if c not in df.columns:
            df[c] = pd.NA

    df = (
        df.assign(day_col=lambda d: "Day " + d["actual_date"].astype(str))
            .pivot_table(
                index=["friend_viewer_id", "friend_name"],
                columns="day_col",
                values="adjusted_interpolated_fan_gain",
                aggfunc="first"
            )
            .reset_index()
    )
    df.columns.name = None

    def _day_num(x: str):
        if not isinstance(x, str) or not x.startswith("Day "):
            return None
        try:
            return int(x.split(maxsplit=1)[1])
        except Exception:
            return None

    day_cols = [c for c in df.columns if isinstance(c, str) and c.startswith("Day ")]

    # --- Keep only members who have value on the newest day (max Day N) ---
    nums = [n for n in map(_day_num, day_cols) if n is not None]
    if nums:
        latest_day = max(nums)
        latest_col = f"Day {latest_day}"
        if latest_col in df.columns:
            df = df[~df[latest_col].isna()].copy()

    # Order Day columns numerically
    day_cols = sorted(day_cols, key=lambda c: (_day_num(c) if _day_num(c) is not None else float("inf")))

    # Compute AVG/d and finalize columns
    df["AVG/d"] = df[day_cols].mean(axis=1).round(0) if day_cols else 0
    df = df[["friend_viewer_id", "friend_name", "AVG/d"] + day_cols].rename(
        columns={"friend_viewer_id": "Member_ID", "friend_name": "Member_Name"}
    )
    df["Member_ID"] = df["Member_ID"].fillna("").astype(str)
    df["Member_Name"] = df["Member_Name"].fillna("").astype(str)
    for c in df.columns:
        if c not in ("Member_ID", "Member_Name"):
            df[c] = pd.to_numeric(df[c], errors="coerce")

    df = df.sort_values(["AVG/d", "Member_Name"], ascending=[False, True], kind="mergesort").reset_index(drop=True)
    return df


# === Google Sheets export ===
def export_to_gsheets(df: pd.DataFrame, spreadsheet_id: str, sheet_title: str, threshold: int):
    from gspread.utils import rowcol_to_a1

    # ====== PREP DATA ======
    GAP_COL = " "
    dcols = [c for c in df.columns if isinstance(c, str) and c.startswith("Day ")]
    df_to_write = df.copy()

    # Add Total and a blue gap column before it
    if dcols:
        df_to_write["Total"] = df_to_write[dcols].sum(axis=1, min_count=1)
        gidx = df_to_write.columns.get_loc("Total")
        df_to_write.insert(gidx, GAP_COL, "")
    else:
        gidx = None

# Bottom "Total" row (sum)
    bottom_totals = {}
    for c in df_to_write.columns:
        if c == "Member_Name":
            bottom_totals[c] = "Total"
        elif c in ("Member_ID", GAP_COL):
            bottom_totals[c] = ""
        else:
            total = pd.to_numeric(df_to_write[c], errors="coerce").sum(min_count=1)
            if pd.isna(total):
                bottom_totals[c] = ""
            elif isinstance(total, float):
                bottom_totals[c] = total  
            elif hasattr(total, 'item'):
                bottom_totals[c] = total.item()
            else:
                bottom_totals[c] = total 

    # Day AVG row ‚Äî per-day means only (no AVG/d)
    day_avgs = pd.Series("", index=df_to_write.columns, dtype=object)
    if dcols:
        means = df_to_write[dcols].mean(axis=0, skipna=True).round(0)
        for c in dcols:
            day_avgs[c] = means.get(c, "")
    day_avgs["Member_Name"] = "Day AVG"

    header = list(map(str, df_to_write.columns))
    data_rows = df_to_write.where(pd.notna(df_to_write), "").values.tolist()
    totals_row = [("" if pd.isna(v) else v) for v in (bottom_totals.get(c, "") for c in df_to_write.columns)]
    day_avg_row = [day_avgs.get(c, "") for c in df_to_write.columns]

    # Values order: header, data..., Total, Day AVG
    values = [header] + data_rows + [totals_row, day_avg_row]

    # ====== OPEN SHEET ======
    ss = GC.open_by_key(spreadsheet_id)
    for ws in ss.worksheets():
        if ws.title == sheet_title:
            ss.del_worksheet(ws)
            break
    ws = ss.add_worksheet(title=sheet_title, rows=max(len(values) + 50, 120), cols=max(len(header) + 10, 26))

    # Write values
    end_row = len(values)
    end_col = len(header)
    end_a1 = rowcol_to_a1(end_row, end_col)
    ws.update(values, f"A1:{end_a1}")

    # ====== FORMATTING ======
    sheet_id = ws._properties["sheetId"]
    last_data_row_1based = 1 + len(data_rows)  # header + data (excludes the 2 summary rows)

    header_range = {"sheetId": sheet_id, "startRowIndex": 0, "endRowIndex": 1, "startColumnIndex": 0, "endColumnIndex": end_col}
    totals_range = {"sheetId": sheet_id, "startRowIndex": end_row - 2, "endRowIndex": end_row, "startColumnIndex": 0, "endColumnIndex": end_col}
    header_plus_data_range = {"sheetId": sheet_id, "startRowIndex": 0, "endRowIndex": last_data_row_1based, "startColumnIndex": 0, "endColumnIndex": end_col}
    band_left = {"sheetId": sheet_id, "startRowIndex": 1, "endRowIndex": last_data_row_1based, "startColumnIndex": 0, "endColumnIndex": (gidx if gidx is not None else end_col)}
    band_right = {"sheetId": sheet_id, "startRowIndex": 1, "endRowIndex": last_data_row_1based,
                  "startColumnIndex": (gidx + 1 if gidx is not None else end_col), "endColumnIndex": end_col}
    full_table_range = {"sheetId": sheet_id, "startRowIndex": 0, "endRowIndex": end_row, "startColumnIndex": 0, "endColumnIndex": end_col}

    # Column index helpers
    def col_1_based(col_name: str) -> int | None:
        try:
            return header.index(col_name) + 1
        except ValueError:
            return None

    # Number formatting applies to all numeric columns except id/name/gap
    skip_for_number = {"Member_ID", "Member_Name", GAP_COL}
    numeric_cols_1 = [i + 1 for i, c in enumerate(header) if c not in skip_for_number]

    # Conditional threshold: Day columns + AVG/d (data rows only).
    day_cols_1 = [col_1_based(c) for c in dcols]
    day_cols_1 = [c1 for c1 in day_cols_1 if c1 is not None]

    def col_range_rows(start_row_1, end_row_1, col_1):
        return {"sheetId": sheet_id, "startRowIndex": start_row_1 - 1, "endRowIndex": end_row_1,
                "startColumnIndex": col_1 - 1, "endColumnIndex": col_1}

    numeric_ranges_all = [col_range_rows(2, end_row, c1) for c1 in numeric_cols_1]
    numeric_ranges_data_days = [col_range_rows(2, last_data_row_1based, c1) for c1 in day_cols_1]

    # NEW: add AVG/d to the threshold-based red rule (data rows only)
    avgd_col_1 = col_1_based("AVG/d")
    numeric_ranges_data = list(numeric_ranges_data_days)
    if avgd_col_1 is not None:
        numeric_ranges_data.append(col_range_rows(2, last_data_row_1based, avgd_col_1))

    blue_fill  = {"red": 0.31, "green": 0.51, "blue": 0.74}
    white_font = {"red": 1, "green": 1, "blue": 1}
    red_fill   = {"red": 1.00, "green": 0.78, "blue": 0.81}
    grey_fill  = {"red": 0.75, "green": 0.75, "blue": 0.75}
    band_light = {"red": 0.86, "green": 0.92, "blue": 0.97}
    band_very  = {"red": 0.95, "green": 0.97, "blue": 0.98}
    number_format = {"type": "NUMBER", "pattern": "#,##0"}

    requests = [
        {"setBasicFilter": {"filter": {"range": header_plus_data_range}}},

        # Header styling
        {
            "repeatCell": {
                "range": header_range,
                "cell": {"userEnteredFormat": {
                    "backgroundColor": blue_fill,
                    "textFormat": {"bold": True, "foregroundColor": white_font},
                    "horizontalAlignment": "CENTER",
                    "verticalAlignment": "MIDDLE"
                }},
                "fields": "userEnteredFormat(backgroundColor,textFormat,horizontalAlignment,verticalAlignment)"
            }
        },

        # Style both "Total" and "Day AVG" rows
        {
            "repeatCell": {
                "range": totals_range,
                "cell": {"userEnteredFormat": {"backgroundColor": blue_fill, "textFormat": {"bold": True, "foregroundColor": white_font}}},
                "fields": "userEnteredFormat(backgroundColor,textFormat)"
            }
        },

        # GAP column blue & narrow
        *([
            {
                "repeatCell": {
                    "range": {"sheetId": sheet_id, "startRowIndex": 0, "endRowIndex": end_row, "startColumnIndex": gidx, "endColumnIndex": gidx + 1},
                    "cell": {"userEnteredFormat": {"backgroundColor": blue_fill}},
                    "fields": "userEnteredFormat.backgroundColor"
                }
            },
            {
                "updateDimensionProperties": {
                    "range": {"sheetId": sheet_id, "dimension": "COLUMNS", "startIndex": gidx, "endIndex": gidx + 1},
                    "properties": {"pixelSize": 40},
                    "fields": "pixelSize"
                }
            }
        ] if gidx is not None else []),

        # Alternating banded rows (data only)
        *([
            {"addBanding": {"bandedRange": {"range": band_left,  "rowProperties": {"firstBandColor": band_light, "secondBandColor": band_very}}}}
        ] if gidx is None or gidx > 0 else []),
        *([
            {"addBanding": {"bandedRange": {"range": band_right, "rowProperties": {"firstBandColor": band_light, "secondBandColor": band_very}}}}
        ] if gidx is not None and gidx + 1 < end_col else []),

        # Number formatting for all numeric columns (AVG/d, Day N, Total)
        *[
            {"repeatCell": {"range": r, "cell": {"userEnteredFormat": {"numberFormat": number_format}}, "fields": "userEnteredFormat.numberFormat"}}
            for r in numeric_ranges_all
        ],

        # Conditional red (below threshold) ‚Äî Day N columns + AVG/d, data rows only
        *([{
            "addConditionalFormatRule": {
                "rule": {"ranges": numeric_ranges_data,
                         "booleanRule": {"condition": {"type": "NUMBER_LESS",
                                                       "values": [{"userEnteredValue": str(threshold)}]},
                                         "format": {"backgroundColor": red_fill}}},
                "index": 0
            }
        }] if numeric_ranges_data else []),

        # Conditional grey (blanks) ‚Äî ONLY for Day N columns, data rows
        *([{
            "addConditionalFormatRule": {
                "rule": {"ranges": numeric_ranges_data_days,
                         "booleanRule": {"condition": {"type": "BLANK"},
                                         "format": {"backgroundColor": grey_fill}}},
                "index": 0
            }
        }] if numeric_ranges_data_days else []),

        # Borders on all cells
        {
            "updateBorders": {
                "range": full_table_range,
                "top": {"style": "SOLID"},
                "bottom": {"style": "SOLID"},
                "left": {"style": "SOLID"},
                "right": {"style": "SOLID"},
                "innerHorizontal": {"style": "SOLID"},
                "innerVertical": {"style": "SOLID"},
            }
        },
    ]

    # Wider Member_Name (for filter icon space)
    if "Member_Name" in header:
        name_col_index = header.index("Member_Name")
        requests.append({
            "updateDimensionProperties": {
                "range": {"sheetId": sheet_id, "dimension": "COLUMNS", "startIndex": name_col_index, "endIndex": name_col_index + 1},
                "properties": {"pixelSize": 140},
                "fields": "pixelSize"
            }
        })

    # Freeze header
    requests.append({
        "updateSheetProperties": {
            "properties": {"sheetId": sheet_id, "gridProperties": {"frozenRowCount": 1}},
            "fields": "gridProperties.frozenRowCount"
        }
    })

    ws.spreadsheet.batch_update({"requests": requests})

# === Core Export Logic (Single Club) ===
async def process_and_export_club(cfg: dict, data_or_task_result=None):
    title = cfg['title']
    
    # If data_or_task_result is an Exception (initial fetch error) or needs re-fetching
    if isinstance(data_or_task_result, Exception) or data_or_task_result is None:
        print(f"    (Re-fetching data for {title}...)")
        # This calls the fetch_json function, which contains its own 3-retry logic for connection errors
        data = await fetch_json(cfg["URL"]) 
    else:
        # If data was successfully fetched during the initial concurrent run
        data = data_or_task_result

    # Process and export
    df = build_dataframe(data)
    export_to_gsheets(df, spreadsheet_id=SHEET_ID, sheet_title=title, threshold=cfg["THRESHOLD"])
    return True

# === Main ===
async def main():
    choice = pick_club()
    
    # Define retry parameters
    MAX_CLUB_RETRIES = 3  
    CLUB_RETRY_DELAY = 5
    
    if choice == "ALL":
        print("\n‚ö° Exporting ALL clubs: Concurrent data fetching, Sequential processing/Export with in-place retry to maintain order...\n")
        
        # 1. Concurrent data fetching
        print("--- 1. Fetching All Data Concurrently ---")
        fetch_tasks = {
            key: asyncio.create_task(fetch_json(cfg["URL"])) 
            for key, cfg in CLUBS.items()
        }
        
        # Wait for all to complete (store results or exceptions)
        results = await asyncio.gather(*fetch_tasks.values(), return_exceptions=True)
        results_map = {key: results[i] for i, key in enumerate(CLUBS.keys())}
        
        # 2. Sequential Processing and Export with In-Place Retry
        print("\n--- 2. Processing and Exporting Sequentially with Retry ---")
        clubs_failed = []
        
        for key, cfg in CLUBS.items():
            title = cfg["title"]
            initial_result = results_map[key]
            
            # High-level retry loop
            for attempt in range(MAX_CLUB_RETRIES):
                if attempt > 0:
                    print(f"\n‚ö° Retrying club {title} (Attempt {attempt + 1}/{MAX_CLUB_RETRIES}) after waiting {CLUB_RETRY_DELAY}s...")
                    await asyncio.sleep(CLUB_RETRY_DELAY)
                
                try:
                    # Attempt 1: Use the initial concurrent fetch result.
                    # Subsequent attempts (Retry): Re-fetch the data (None will trigger fetch_json inside)
                    data_to_use = initial_result if attempt == 0 and not isinstance(initial_result, Exception) else None
                    
                    await process_and_export_club(cfg, data_or_task_result=data_to_use)
                    
                    if attempt == 0:
                         print(f"‚úÖ {title} exported successfully.")
                    else:
                         print(f"‚úÖ {title} exported successfully after {attempt} retry(ies).")
                    break # Success, move to the next club
                        
                except Exception as e:
                    # Failure could be from fetch_json (final attempt) or gspread/processing error
                    print(f"‚ùå {title} failed on attempt {attempt + 1}: {e}")
                    if attempt == MAX_CLUB_RETRIES - 1:
                        clubs_failed.append(title)
                    # If not the final attempt, the loop continues (wait and retry)
        
        print("\n" + "="*50)
        if clubs_failed:
            print(f"‚ö†Ô∏è COMPLETED WITH ERRORS: {len(clubs_failed)} club(s) failed after {MAX_CLUB_RETRIES} attempts.")
            print("    List of failed clubs: " + ", ".join(clubs_failed))
        else:
            print("üéâ COMPLETED: All clubs were exported successfully in order!")
        print("="*50)
    
    else:
        cfg = choice
        print(f"\nSelected: {cfg['title']}\nURL: {cfg['URL']}\nSheet: {SHEET_ID}\nThreshold: {cfg['THRESHOLD']}\n")

        await export_single_club_with_retry_v2(cfg, MAX_CLUB_RETRIES, CLUB_RETRY_DELAY)

# === Main logic for single club with retry (for the single choice path) ===
async def export_single_club_with_retry_v2(cfg: dict, max_retries: int, retry_delay: int):
    title = cfg['title']
    for attempt in range(max_retries):
        if attempt > 0:
            print(f"\n‚ö° Retrying full process for {title} (Attempt {attempt + 1}/{max_retries})...")
            
        try:
            # Initial data is None to always trigger fetch_json inside
            await process_and_export_club(cfg, data_or_task_result=None)
            
            if attempt == 0:
                print(f"‚úÖ Exported single club '{title}' successfully!")
            else:
                print(f"‚úÖ Exported single club '{title}' successfully after {attempt} retry(ies)!")
                
            return True
            
        except Exception as e:
            print(f"‚ùå Club '{title}' failed on attempt {attempt + 1}: {e}")
            if attempt < max_retries - 1:
                print(f"    Waiting {retry_delay}s before next retry...")
                await asyncio.sleep(retry_delay)
            else:
                print(f"    Final failure for {title} after {max_retries} attempts.")
                return False

# Updated main entry function for ALL/Single logic
async def main_updated():
    choice = pick_club()
    
    MAX_CLUB_RETRIES = 3
    CLUB_RETRY_DELAY = 5
    
    if choice == "ALL":
        # Run ALL logic
        print("\n‚ö° Exporting ALL clubs: Concurrent data fetching, Sequential processing/Export with in-place retry to maintain order...\n")
        
        # 1. Concurrent data fetching
        print("--- 1. Fetching All Data Concurrently ---")
        fetch_tasks = {
            key: asyncio.create_task(fetch_json(cfg["URL"])) 
            for key, cfg in CLUBS.items()
        }
        
        results = await asyncio.gather(*fetch_tasks.values(), return_exceptions=True)
        results_map = {key: results[i] for i, key in enumerate(CLUBS.keys())}
        
        # 2. Sequential Processing and Export with In-Place Retry
        print("\n--- 2. Processing and Exporting Sequentially with Retry ---")
        clubs_failed = []
        
        for key, cfg in CLUBS.items():
            title = cfg["title"]
            initial_result = results_map[key]
            
            for attempt in range(MAX_CLUB_RETRIES):
                if attempt > 0:
                    print(f"\n‚ö° Retrying club {title} (Attempt {attempt + 1}/{MAX_CLUB_RETRIES}) after waiting {CLUB_RETRY_DELAY}s...")
                    await asyncio.sleep(CLUB_RETRY_DELAY)
                
                try:
                    data_to_use = initial_result if attempt == 0 and not isinstance(initial_result, Exception) else None
                    
                    await process_and_export_club(cfg, data_or_task_result=data_to_use)
                    
                    if attempt == 0:
                         print(f"‚úÖ {title} exported successfully.")
                    else:
                         print(f"‚úÖ {title} exported successfully after {attempt} retry(ies).")
                    break
                        
                except Exception as e:
                    print(f"‚ùå {title} failed on attempt {attempt + 1}: {e}")
                    if attempt == MAX_CLUB_RETRIES - 1:
                        clubs_failed.append(title)
        
        print("\n" + "="*50)
        if clubs_failed:
            print(f"‚ö†Ô∏è COMPLETED WITH ERRORS: {len(clubs_failed)} club(s) failed after {MAX_CLUB_RETRIES} attempts.")
            print("    List of failed clubs: " + ", ".join(clubs_failed))
        else:
            print("üéâ COMPLETED: All clubs were exported successfully in order!")
        print("="*50)

    else:
        # Run Single club logic
        cfg = choice
        print(f"\nSelected: {cfg['title']}\nURL: {cfg['URL']}\nSheet: {SHEET_ID}\nThreshold: {cfg['THRESHOLD']}\n")
        
        await export_single_club_with_retry_v2(cfg, MAX_CLUB_RETRIES, CLUB_RETRY_DELAY)


async def run_automatic_export():
    """Ch·∫°y to√†n b·ªô logic export cho T·∫§T C·∫¢ c√°c c√¢u l·∫°c b·ªô (t∆∞∆°ng ƒë∆∞∆°ng v·ªõi ch·ªçn '0')."""
    print("==================================================")
    print(f"‚ú® Starting scheduled ALL clubs export at {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("==================================================")
    
    # ƒê·ªãnh nghƒ©a tham s·ªë retry (c√≥ th·ªÉ l·∫•y t·ª´ globals n·∫øu c·∫ßn)
    MAX_CLUB_RETRIES = 3 
    CLUB_RETRY_DELAY = 5
    
    # 1. Concurrent data fetching (gi·ªëng logic ALL trong main_updated)
    print("--- 1. Fetching All Data Concurrently ---")
    fetch_tasks = {
        key: asyncio.create_task(fetch_json(cfg["URL"])) 
        for key, cfg in CLUBS.items()
    }
    # ... (ph·∫ßn c√≤n l·∫°i c·ªßa logic ch·∫°y ALL trong main_updated) ...
    # ... (Ch√®n to√†n b·ªô logic ALL ·ªü ƒë√¢y) ...
    
    results = await asyncio.gather(*fetch_tasks.values(), return_exceptions=True)
    results_map = {key: results[i] for i, key in enumerate(CLUBS.keys())}
    
    # 2. Sequential Processing and Export with In-Place Retry
    print("\n--- 2. Processing and Exporting Sequentially with Retry ---")
    clubs_failed = []
    
    for key, cfg in CLUBS.items():
        title = cfg["title"]
        initial_result = results_map[key]
        
        for attempt in range(MAX_CLUB_RETRIES):
            if attempt > 0:
                print(f"\n‚ö° Retrying club {title} (Attempt {attempt + 1}/{MAX_CLUB_RETRIES}) after waiting {CLUB_RETRY_DELAY}s...")
                await asyncio.sleep(CLUB_RETRY_DELAY)
            
            try:
                data_to_use = initial_result if attempt == 0 and not isinstance(initial_result, Exception) else None
                
                await process_and_export_club(cfg, data_or_task_result=data_to_use)
                
                if attempt == 0:
                    print(f"‚úÖ {title} exported successfully.")
                else:
                    print(f"‚úÖ {title} exported successfully after {attempt} retry(ies).")
                break
                
            except Exception as e:
                print(f"‚ùå {title} failed on attempt {attempt + 1}: {e}")
                if attempt == MAX_CLUB_RETRIES - 1:
                    clubs_failed.append(title)

    
    print("\n" + "="*50)
    if clubs_failed:
        print(f"‚ö†Ô∏è COMPLETED WITH ERRORS: {len(clubs_failed)} club(s) failed after {MAX_CLUB_RETRIES} attempts.")
        print("     List of failed clubs: " + ", ".join(clubs_failed))
    else:
        print("üéâ COMPLETED: All clubs were exported successfully in order!")
    print("="*50)